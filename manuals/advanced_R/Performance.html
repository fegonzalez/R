<!DOCTYPE html>
<html>
  <head>
    <title>Performance &middot; Advanced R.</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="www/bootstrap.min.css" rel="stylesheet">
    <link href="www/highlight.css" rel="stylesheet">

    <link href='http://fonts.googleapis.com/css?family=Inconsolata:400,700'
      rel='stylesheet' type='text/css'>
  </head>

  <body>

    <div class="container">

      <div class="masthead">
        <ul class="nav nav-pills pull-right">
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown">
              Table of contents<b class="caret"></b>
            </a>
            <ul class="dropdown-menu pull-right" role="menu">
              <li><a href="Introduction.html">Introduction</a></li>
<li class="dropdown-header">Foundations</li>
<li><a href="Data-structures.html">Data structures</a></li>
<li><a href="Subsetting.html">Subsetting</a></li>
<li><a href="Vocabulary.html">Vocabulary</a></li>
<li><a href="Style.html">Style</a></li>
<li><a href="Functions.html">Functions</a></li>
<li><a href="OO-essentials.html">OO field guide</a></li>
<li><a href="Environments.html">Environments</a></li>
<li><a href="Exceptions-Debugging.html">Exceptions and debugging</a></li>

<li class="dropdown-header">Functional programming</li>
<li><a href="Functional-programming.html">Functional programming</a></li>
<li><a href="Functionals.html">Functionals</a></li>
<li><a href="Function-operators.html">Function operators</a></li>

<li class="dropdown-header">Metaprogramming</li>
<li><a href="Computing-on-the-language.html">Non-standard evaluation</a></li>
<li><a href="Expressions.html">Expressions</a></li>
<li><a href="dsl.html">Domain specific languages</a></li>

<li class="dropdown-header">Performant code</li>
<li><a href="Performance.html">Performance</a></li>
<li><a href="Profiling.html">Profiling</a></li>
<li><a href="memory.html">Memory</a></li>
<li><a href="Rcpp.html">Rcpp</a></li>
<li><a href="C-interface.html">R's C interface</a></li>

            </ul>
          </li>
        </ul>

        <h3 class="muted"><a href="/">Advanced R</a> <small>by Hadley Wickham</small></h3>
        <hr>
      </div>

      <div class="row">
        <div class="col-xs-12 col-sm-3" id="nav">
        <div class="well">
          Want to learn from me in person? I'm next teaching in <a href="https://rstudio-chicago.eventbrite.com">Chicago, May 27-28</a>.
        </div>

        <div class="well">
          Want a physical copy of this material? <a href="http://amzn.com/1466586966?tag=devtools-20">Buy a book from amazon!</a>.
        </div>

        <h4>Contents</h4>
          <ul class="list-unstyled" id="toc"></ul>

          <hr>
          <p><a href="/contribute.html">How to contribute</a></p>

          <p><a class="btn btn-primary" href="https://github.com/hadley/adv-r/edit/master/Performance.rmd">Edit this page</a></p>
        </div>

        <div id="content" class="col-xs-12 col-sm-8 pull-right">
          <h1 id="performance">Performance</h1>
<p>R is not a fast language. This is not an accident. R was purposely designed to make data analysis and statistics easier for you to do. It was not designed to make life easier for your computer. While R is slow compared to other programming languages, for most purposes, it’s fast enough. </p>
<p>The goal of this part of the book is to give you a deeper understanding of R’s performance characteristics. In this chapter, you’ll learn about some of the trade-offs that R has made, valuing flexibility over performance. The following four chapters will give you the skills to improve the speed of your code when you need to:</p>
<ul>
<li><p>In <a href="Profiling.html#profiling">Profiling</a>, you’ll learn how to systematically make your code faster. First you figure what’s slow, and then you apply some general techniques to make the slow parts faster.</p></li>
<li><p>In <a href="memory.html#memory">Memory</a>, you’ll learn about how R uses memory, and how garbage collection and copy-on-modify affect performance and memory usage.</p></li>
<li><p>For really high-performance code, you can move outside of R and use another programming language. <a href="Rcpp.html#rcpp">Rcpp</a> will teach you the absolute minimum you need to know about C++ so you can write fast code using the Rcpp package.</p></li>
<li><p>To really understand the performance of built-in base functions, you’ll need to learn a little bit about R’s C API. In <a href="C-interface.html#c-api">R’s C interface</a>, you’ll learn a little about R’s C internals.</p></li>
</ul>
<p>Let’s get started by learning more about why R is slow.</p>
<h2 id="why-is-r-slow">Why is R slow?</h2>
<p>To understand R’s performance, it helps to think about R as both a language and as an implementation of that language. The R-language is abstract: it defines what R code means and how it should work. The implementation is concrete: it reads R code and computes a result. The most popular implementation is the one from <a href="http://r-project.org">r-project.org</a>. I’ll call that implementation GNU-R to distinguish it from R-language, and from the other implementations I’ll discuss later in the chapter. </p>
<p>The distinction between R-language and GNU-R is a bit murky because the R-language is not formally defined. While there is the <a href="http://cran.r-project.org/doc/manuals/R-lang.html">R language definition</a>, it is informal and incomplete. The R-language is mostly defined in terms of how GNU-R works. This is in contrast to other languages, like <a href="http://isocpp.org/std/the-standard">C++</a> and <a href="http://www.ecma-international.org/publications/standards/Ecma-262.htm">javascript</a>, that make a clear distinction between language and implementation by laying out formal specifications that describe in minute detail how every aspect of the language should work. Nevertheless, the distinction between R-language and GNU-R is still useful: poor performance due to the language is hard to fix without breaking existing code; fixing poor performance due to the implementation is easier.</p>
<p>In <a href="Performance.html#language-performance">Language performance</a>, I discuss some of the ways in which the design of the R-language imposes fundamental constraints on R’s speed. In <a href="Performance.html#implementation-performance">Implementation performance</a>, I discuss why GNU-R is currently far from the theoretical maximum, and why improvements in performance happen so slowly. While it’s hard to know exactly how much faster a better implementation could be, a &gt;10x improvement in speed seems achievable. In <a href="Performance.html#faster-r">alternative implementations</a>, I discuss some of the promising new implementations of R, and describe one important technique they use to make R code run faster.</p>
<p>Beyond performance limitations due to design and implementation, it has to be said that a lot of R code is slow simply because it’s poorly written. Few R users have any formal training in programming or software development. Fewer still write R code for a living. Most people use R to understand data: it’s more important to get an answer quickly than to develop a system that will work in a wide variety of situations. This means that it’s relatively easy to make most R code much faster, as we’ll see in the following chapters.</p>
<p>Before we examine some of the slower parts of the R-language and GNU-R, we need to learn a little about benchmarking so that we can give our intuitions about performance a concrete foundation.</p>
<h2 id="microbenchmarking">Microbenchmarking</h2>
<p>A microbenchmark is a measurement of the performance of a very small piece of code, something that might take microseconds (µs) or nanoseconds (ns) to run. I’m going to use microbenchmarks to demonstrate the performance of very low-level pieces of R code, which help develop your intuition for how R works. This intuition, by-and-large, is not useful for increasing the speed of real code. The observed differences in microbenchmarks will typically be dominated by higher-order effects in real code; a deep understanding of subatomic physics is not very helpful when baking. Don’t change the way you code because of these microbenchmarks. Instead wait until you’ve read the practical advice in the following chapters. </p>
<p>The best tool for microbenchmarking in R is the <a href="http://cran.r-project.org/web/packages/microbenchmark/">microbenchmark</a> package. It provides very precise timings, making it possible to compare operations that only take a tiny amount of time. For example, the following code compares the speed of two ways of computing a square root.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(microbenchmark)

x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>)
<span class="kw">microbenchmark</span>(
  <span class="kw">sqrt</span>(x),
  x ^<span class="st"> </span><span class="fl">0.5</span>
)
<span class="co">#&gt; Unit: nanoseconds</span>
<span class="co">#&gt;     expr    min     lq  mean median     uq    max neval</span>
<span class="co">#&gt;  sqrt(x)  1,390  1,660  2151  1,830  2,040 28,100   100</span>
<span class="co">#&gt;    x^0.5 12,700 13,000 15853 15,700 16,000 67,500   100</span></code></pre>
<p>By default, <code>microbenchmark()</code> runs each expression 100 times (controlled by the <code>times</code> parameter). In the process, it also randomises the order of the expressions. It summarises the results with a minimum (<code>min</code>), lower quartile (<code>lq</code>), median, upper quartile (<code>uq</code>), and maximum (<code>max</code>). Focus on the median, and use the upper and lower quartiles (<code>lq</code> and <code>uq</code>) to get a feel for the variability. In this example, you can see that using the special purpose <code>sqrt()</code> function is faster than the general exponentiation operator.</p>
<p>As with all microbenchmarks, pay careful attention to the units: each computation takes about 800 ns, 800 billionths of a second. To help calibrate the impact of a microbenchmark on run time, it’s useful to think about how many times a function needs to run before it takes a second. If a microbenchmark takes:</p>
<ul>
<li>1 ms, then one thousand calls takes a second</li>
<li>1 µs, then one million calls takes a second</li>
<li>1 ns, then one billion calls takes a second</li>
</ul>
<p>The <code>sqrt()</code> function takes about 800 ns, or 0.8 µs, to compute the square root of 100 numbers. That means if you repeated the operation a million times, it would take 0.8 s. So changing the way you compute the square root is unlikely to significantly affect real code.</p>
<h3>Exercises</h3>
<ol style="list-style-type: decimal">
<li><p>Instead of using <code>microbenchmark()</code>, you could use the built-in function <code>system.time()</code>. But <code>system.time()</code> is much less precise, so you’ll need to repeat each operation many times with a loop, and then divide to find the average time of each operation, as in the code below.</p>
<pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1</span>:<span class="fl">1e6</span>
<span class="kw">system.time</span>(for (i in n) <span class="kw">sqrt</span>(x)) /<span class="st"> </span><span class="kw">length</span>(n)
<span class="kw">system.time</span>(for (i in n) x ^<span class="st"> </span><span class="fl">0.5</span>) /<span class="st"> </span><span class="kw">length</span>(n)</code></pre>
<p>How do the estimates from <code>system.time()</code> compare to those from <code>microbenchmark()</code>? Why are they different?</p></li>
<li><p>Here are two other ways to compute the square root of a vector. Which do you think will be fastest? Which will be slowest? Use microbenchmarking to test your answers.</p>
<pre class="sourceCode r"><code class="sourceCode r">x ^<span class="st"> </span>(<span class="dv">1</span> /<span class="st"> </span><span class="dv">2</span>)
<span class="kw">exp</span>(<span class="kw">log</span>(x) /<span class="st"> </span><span class="dv">2</span>)</code></pre></li>
<li><p>Use microbenchmarking to rank the basic arithmetic operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, and <code>^</code>) in terms of their speed. Visualise the results. Compare the speed of arithmetic on integers vs. doubles.</p></li>
<li><p>You can change the units in which the microbenchmark results are expressed with the <code>unit</code> parameter. Use <code>unit = &quot;eps&quot;</code> to show the number of evaluations needed to take 1 second. Repeat the benchmarks above with the eps unit. How does this change your intuition for performance?</p></li>
</ol>
<h2 id="language-performance">Language performance</h2>
<p>In this section, I’ll explore three trade-offs that limit the performance of the R-language: extreme dynamism, name lookup with mutable environments, and lazy evaluation of function arguments. I’ll illustrate each trade-off with a microbenchmark, showing how it slows GNU-R down. I benchmark GNU-R because you can’t benchmark the R-language (it can’t run code). This means that the results are only suggestive of the cost of these design decisions, but are nevertheless useful. I’ve picked these three examples to illustrate some of the trade-offs that are key to language design: the designer must balance speed, flexibility, and ease of implementation.</p>
<p>If you’d like to learn more about the performance characteristics of the R-language and how they affect real code, I highly recommend <a href="http://r.cs.purdue.edu/pub/ecoop12.pdf">“Evaluating the Design of the R Language”</a> by Floreal Morandat, Brandon Hill, Leo Osvald, and Jan Vitek. It uses a powerful methodology that combines a modified R interpreter and a wide set of code found in the wild.</p>
<h3 id="extreme-dynamism">Extreme dynamism</h3>
<p>R is an extremely dynamic programming language. Almost anything can be modified after it is created. To give just a few examples, you can:</p>
<ul>
<li>Change the body, arguments, and environment of functions.</li>
<li>Change the S4 methods for a generic.</li>
<li>Add new fields to an S3 object, or even change its class.</li>
<li>Modify objects outside of the local environment with <code>&lt;&lt;-</code>.</li>
</ul>
<p>Pretty much the only things you can’t change are objects in sealed namespaces, which are created when you load a package.</p>
<p>The advantage of dynamism is that you need minimal upfront planning. You can change your mind at any time, iterating your way to a solution without having to start afresh. The disadvantage of dynamism is that it’s difficult to predict exactly what will happen with a given function call. This is a problem because the easier it is to predict what’s going to happen, the easier it is for an interpreter or compiler to make an optimisation. (If you’d like more details, Charles Nutter expands on this idea at <a href="http://blog.headius.com/2013/05/on-languages-vms-optimization-and-way.html">On Languages, VMs, Optimization, and the Way of the World</a>.) If an interpreter can’t predict what’s going to happen, it has to consider many options before it finds the right one. For example, the following loop is slow in R, because R doesn’t know that <code>x</code> is always an integer. That means R has to look for the right <code>+</code> method (i.e., is it adding doubles, or integers?) in every iteration of the loop.</p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span>0L
for (i in <span class="dv">1</span>:<span class="fl">1e6</span>) {
  x &lt;-<span class="st"> </span>x +<span class="st"> </span><span class="dv">1</span>
}</code></pre>
<p>The cost of finding the right method is higher for non-primitive functions. The following microbenchmark illustrates the cost of method dispatch for S3, S4, and RC. I create a generic and a method for each OO system, then call the generic and see how long it takes to find and call the method. I also time how long it takes to call the bare function for comparison. </p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span>function(x) <span class="ot">NULL</span>

s3 &lt;-<span class="st"> </span>function(x) <span class="kw">UseMethod</span>(<span class="st">&quot;s3&quot;</span>)
s3.integer &lt;-<span class="st"> </span>f

A &lt;-<span class="st"> </span><span class="kw">setClass</span>(<span class="st">&quot;A&quot;</span>, <span class="kw">representation</span>(<span class="dt">a =</span> <span class="st">&quot;list&quot;</span>))
<span class="kw">setGeneric</span>(<span class="st">&quot;s4&quot;</span>, function(x) <span class="kw">standardGeneric</span>(<span class="st">&quot;s4&quot;</span>))
<span class="kw">setMethod</span>(s4, <span class="st">&quot;A&quot;</span>, f)

B &lt;-<span class="st"> </span><span class="kw">setRefClass</span>(<span class="st">&quot;B&quot;</span>, <span class="dt">methods =</span> <span class="kw">list</span>(<span class="dt">rc =</span> f))

a &lt;-<span class="st"> </span><span class="kw">A</span>()
b &lt;-<span class="st"> </span>B$<span class="kw">new</span>()</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">microbenchmark</span>(
  <span class="dt">fun =</span> <span class="kw">f</span>(),
  <span class="dt">S3 =</span> <span class="kw">s3</span>(1L),
  <span class="dt">S4 =</span> <span class="kw">s4</span>(a),
  <span class="dt">RC =</span> b$<span class="kw">rc</span>()
)
<span class="co">#&gt; Unit: nanoseconds</span>
<span class="co">#&gt;  expr    min     lq  mean median     uq     max neval</span>
<span class="co">#&gt;   fun    207    358   491    446    508   2,670   100</span>
<span class="co">#&gt;    S3  3,480  4,280  5008  4,760  5,050  30,600   100</span>
<span class="co">#&gt;    S4 15,400 19,300 21022 20,200 20,900  62,900   100</span>
<span class="co">#&gt;    RC 17,600 19,300 31175 23,100 23,900 834,000   100</span></code></pre>
<p>On my computer, the bare function takes about 200 ns. S3 method dispatch takes an additional 2,000 ns; S4 dispatch, 11,000 ns; and RC dispatch, 10,000 ns. S3 and S4 method dispatch are expensive because R must search for the right method every time the generic is called; it might have changed between this call and the last. R could do better by caching methods between calls, but caching is hard to do correctly and a notorious source of bugs.</p>
<h3>Name lookup with mutable environments</h3>
<p>It’s surprisingly difficult to find the value associated with a name in the R-language. This is due to combination of lexical scoping and extreme dynamism. Take the following example. Each time we print <code>a</code> it comes from a different environment: </p>
<pre class="sourceCode r"><code class="sourceCode r">a &lt;-<span class="st"> </span><span class="dv">1</span>
f &lt;-<span class="st"> </span>function() {
  g &lt;-<span class="st"> </span>function() {
    <span class="kw">print</span>(a)
    <span class="kw">assign</span>(<span class="st">&quot;a&quot;</span>, <span class="dv">2</span>, <span class="dt">envir =</span> <span class="kw">parent.frame</span>())
    <span class="kw">print</span>(a)
    a &lt;-<span class="st"> </span><span class="dv">3</span>
    <span class="kw">print</span>(a)
  }
  <span class="kw">g</span>()
}
<span class="kw">f</span>()
<span class="co">#&gt; [1] 1</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; [1] 3</span></code></pre>
<p>This means that you can’t do name lookup just once: you have to start from scratch each time. This problem is exacerbated by the fact that almost every operation is a lexically scoped function call. You might think the following simple function calls two functions: <code>+</code> and <code>^</code>. In fact, it calls four because <code>{</code> and <code>(</code> are regular functions in R.</p>
<pre class="sourceCode r"><code class="sourceCode r">f &lt;-<span class="st"> </span>function(x, y) {
  (x +<span class="st"> </span>y) ^<span class="st"> </span><span class="dv">2</span>
}</code></pre>
<p>Since these functions are in the global environment, R has to look through every environment in the search path, which could easily be 10 or 20 environments. The following microbenchmark hints at the performance costs. We create four versions of <code>f()</code>, each with one more environment (containing 26 bindings) between the environment of <code>f()</code> and the base environment where <code>+</code>, <code>^</code>, <code>(</code>, and <code>{</code> are defined.</p>
<pre class="sourceCode r"><code class="sourceCode r">random_env &lt;-<span class="st"> </span>function(<span class="dt">parent =</span> <span class="kw">globalenv</span>()) {
  letter_list &lt;-<span class="st"> </span><span class="kw">setNames</span>(<span class="kw">as.list</span>(<span class="kw">runif</span>(<span class="dv">26</span>)), LETTERS)
  <span class="kw">list2env</span>(letter_list, <span class="dt">envir =</span> <span class="kw">new.env</span>(<span class="dt">parent =</span> parent))
}
set_env &lt;-<span class="st"> </span>function(f, e) {
  <span class="kw">environment</span>(f) &lt;-<span class="st"> </span>e
  f
}
f2 &lt;-<span class="st"> </span><span class="kw">set_env</span>(f, <span class="kw">random_env</span>())
f3 &lt;-<span class="st"> </span><span class="kw">set_env</span>(f, <span class="kw">random_env</span>(<span class="kw">environment</span>(f2)))
f4 &lt;-<span class="st"> </span><span class="kw">set_env</span>(f, <span class="kw">random_env</span>(<span class="kw">environment</span>(f3)))

<span class="kw">microbenchmark</span>(
  <span class="kw">f</span>(<span class="dv">1</span>, <span class="dv">2</span>),
  <span class="kw">f2</span>(<span class="dv">1</span>, <span class="dv">2</span>),
  <span class="kw">f3</span>(<span class="dv">1</span>, <span class="dv">2</span>),
  <span class="kw">f4</span>(<span class="dv">1</span>, <span class="dv">2</span>),
  <span class="dt">times =</span> <span class="dv">10000</span>
)
<span class="co">#&gt; Unit: nanoseconds</span>
<span class="co">#&gt;      expr   min    lq mean median    uq       max neval</span>
<span class="co">#&gt;   f(1, 2)   860 1,130 1567  1,240 1,330 1,530,000 10000</span>
<span class="co">#&gt;  f2(1, 2)   918 1,210 1487  1,320 1,420    35,100 10000</span>
<span class="co">#&gt;  f3(1, 2) 1,000 1,290 1743  1,420 1,510 1,720,000 10000</span>
<span class="co">#&gt;  f4(1, 2) 1,080 1,400 1667  1,520 1,610    30,200 10000</span></code></pre>
<p>Each additional environment between <code>f()</code> and the base environment makes the function slower by about 30 ns.</p>
<p>It might be possible to implement a caching system so that R only needs to look up the value of each name once. This is hard because there are so many ways to change the value associated with a name: <code>&lt;&lt;-</code>, <code>assign()</code>, <code>eval()</code>, and so on. Any caching system would have to know about these functions to make sure the cache was correctly invalidated and you didn’t get an out-of-date value. </p>
<p>Another simple fix would be to add more built-in constants that you can’t override. This, for example, would mean that R always knew exactly what <code>+</code>, <code>-</code>, <code>{</code>, and <code>(</code> meant, and you wouldn’t have to repeatedly look up their definitions. That would make the interpreter more complicated (because there are more special cases) and hence harder to maintain, and the language less flexible. This would change the R-language, but it would be unlikely to affect much existing code because it’s such a bad idea to override functions like <code>{</code> and <code>(</code>.</p>
<h3>Lazy evaluation overhead</h3>
<p>In R, function arguments are evaluated lazily (as discussed in <a href="Functions.html#lazy-evaluation">lazy evaluation</a> and <a href="Computing-on-the-language.html#capturing-expressions">capturing expressions</a>). To implement lazy evaluation, R uses a promise object that contains the expression needed to compute the result and the environment in which to perform the computation. Creating these objects has some overhead, so each additional argument to a function decreases its speed a little. </p>
<p>The following microbenchmark compares the runtime of a very simple function. Each version of the function has one additional argument. This suggests that adding an additional argument slows the function down by ~20 ns.</p>
<pre class="sourceCode r"><code class="sourceCode r">f0 &lt;-<span class="st"> </span>function() <span class="ot">NULL</span>
f1 &lt;-<span class="st"> </span>function(<span class="dt">a =</span> <span class="dv">1</span>) <span class="ot">NULL</span>
f2 &lt;-<span class="st"> </span>function(<span class="dt">a =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">1</span>) <span class="ot">NULL</span>
f3 &lt;-<span class="st"> </span>function(<span class="dt">a =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">2</span>, <span class="dt">c =</span> <span class="dv">3</span>) <span class="ot">NULL</span>
f4 &lt;-<span class="st"> </span>function(<span class="dt">a =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">2</span>, <span class="dt">c =</span> <span class="dv">4</span>, <span class="dt">d =</span> <span class="dv">4</span>) <span class="ot">NULL</span>
f5 &lt;-<span class="st"> </span>function(<span class="dt">a =</span> <span class="dv">1</span>, <span class="dt">b =</span> <span class="dv">2</span>, <span class="dt">c =</span> <span class="dv">4</span>, <span class="dt">d =</span> <span class="dv">4</span>, <span class="dt">e =</span> <span class="dv">5</span>) <span class="ot">NULL</span>
<span class="kw">microbenchmark</span>(<span class="kw">f0</span>(), <span class="kw">f1</span>(), <span class="kw">f2</span>(), <span class="kw">f3</span>(), <span class="kw">f4</span>(), <span class="kw">f5</span>(), <span class="dt">times =</span> <span class="dv">10000</span>)
<span class="co">#&gt; Unit: nanoseconds</span>
<span class="co">#&gt;  expr min  lq mean median  uq       max neval</span>
<span class="co">#&gt;  f0() 174 265  364    308 336    17,800 10000</span>
<span class="co">#&gt;  f1() 210 318  454    363 396    22,600 10000</span>
<span class="co">#&gt;  f2() 241 361  557    417 462    37,500 10000</span>
<span class="co">#&gt;  f3() 298 440  668    501 549    22,400 10000</span>
<span class="co">#&gt;  f4() 314 467  779    546 618    24,200 10000</span>
<span class="co">#&gt;  f5() 369 537 1065    609 696 2,060,000 10000</span></code></pre>
<p>In most other programming languages there is little overhead for adding extra arguments. Many compiled languages will even warn you if arguments are never used (like in the above example), and automatically remove them from the function.</p>
<h3>Exercises</h3>
<ol style="list-style-type: decimal">
<li><p><code>scan()</code> has the most arguments (21) of any base function. About how much time does it take to make 21 promises each time scan is called? Given a simple input (e.g., <code>scan(text = &quot;1 2 3&quot;, quiet = T)</code>) what proportion of the total run time is due to creating those promises?</p></li>
<li><p>Read <a href="http://r.cs.purdue.edu/pub/ecoop12.pdf">“Evaluating the Design of the R Language”</a>. What other aspects of the R-language slow it down? Construct microbenchmarks to illustrate.</p></li>
<li><p>How does the performance of S3 method dispatch change with the length of the class vector? How does performance of S4 method dispatch change with number of superclasses? How about RC?</p></li>
<li><p>What is the cost of multiple inheritance and multiple dispatch on S4 method dispatch?</p></li>
<li><p>Why is the cost of name lookup less for functions in the base package?</p></li>
</ol>
<h2 id="implementation-performance">Implementation performance</h2>
<p>The design of the R language limits its maximum theoretical performance, but GNU-R is currently nowhere near that maximum. There are many things that can (and will) be done to improve performance. This section discusses some aspects of GNU-R that are slow not because of their definition, but because of their implementation.</p>
<p>R is over 20 years old. It contains nearly 800,000 lines of code (about 45% C, 19% R, and 17% Fortran). Changes to base R can only be made by members of the R Core Team (or R-core for short). Currently R-core has <a href="http://www.r-project.org/contributors.html">twenty members</a>, but only six are active in day-to-day development. No one on R-core works full time on R. Most are statistics professors who can only spend a relatively small amount of their time on R. Because of the care that must be taken to avoid breaking existing code, R-core tends to be very conservative about accepting new code. It can be frustrating to see R-core reject proposals that would improve performance. However, the overriding concern for R-core is not to make R fast, but to build a stable platform for data analysis and statistics. </p>
<p>Below, I’ll show two small, but illustrative, examples of parts of R that are currently slow but could, with some effort, be made faster. They are not critical parts of base R, but they have been sources of frustration for me in the past. As with all microbenchmarks, these won’t affect the performance of most code, but can be important for special cases.</p>
<h3>Extracting a single value from a data frame</h3>
<p>The following microbenchmark shows seven ways to access a single value (the number in the bottom-right corner) from the built-in <code>mtcars</code> dataset. The variation in performance is startling: the slowest method takes 30x longer than the fastest. There’s no reason that there has to be such a huge difference in performance. It’s simply that no one has had the time to fix it.  </p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">microbenchmark</span>(
  <span class="st">&quot;[32, 11]&quot;</span>      =<span class="st"> </span>mtcars[<span class="dv">32</span>, <span class="dv">11</span>],
  <span class="st">&quot;$carb[32]&quot;</span>     =<span class="st"> </span>mtcars$carb[<span class="dv">32</span>],
  <span class="st">&quot;[[c(11, 32)]]&quot;</span> =<span class="st"> </span>mtcars[[<span class="kw">c</span>(<span class="dv">11</span>, <span class="dv">32</span>)]],
  <span class="st">&quot;[[11]][32]&quot;</span>    =<span class="st"> </span>mtcars[[<span class="dv">11</span>]][<span class="dv">32</span>],
  <span class="st">&quot;.subset2&quot;</span>      =<span class="st"> </span><span class="kw">.subset2</span>(mtcars, <span class="dv">11</span>)[<span class="dv">32</span>]
)
<span class="co">#&gt; Unit: nanoseconds</span>
<span class="co">#&gt;           expr    min     lq  mean median     uq     max neval</span>
<span class="co">#&gt;       [32, 11] 25,900 27,600 33987 32,800 33,900  90,900   100</span>
<span class="co">#&gt;      $carb[32] 13,700 16,100 17659 17,600 18,500  37,600   100</span>
<span class="co">#&gt;  [[c(11, 32)]] 10,800 11,700 14257 13,700 14,500  55,700   100</span>
<span class="co">#&gt;     [[11]][32] 10,400 11,300 17690 13,200 13,900 472,000   100</span>
<span class="co">#&gt;       .subset2    391    681  1037    794    916  10,300   100</span></code></pre>
<h3><code>ifelse()</code>, <code>pmin()</code>, and <code>pmax()</code></h3>
<p>Some base functions are known to be slow. For example, take the following three implementations of <code>squish()</code>, a function that ensures that the smallest value in a vector is at least <code>a</code> and its largest value is at most <code>b</code>. The first implementation, <code>squish_ife()</code>, uses <code>ifelse()</code>. <code>ifelse()</code> is known to be slow because it is relatively general and must evaluate all arguments fully. The second implementation, <code>squish_p()</code>, uses <code>pmin()</code> and <code>pmax()</code>. Because these two functions are so specialised, one might expect that they would be fast. However, they’re actually rather slow. This is because they can take any number of arguments and they have to do some relatively complicated checks to determine which method to use. The final implementation uses basic subassignment.   </p>
<pre class="sourceCode r"><code class="sourceCode r">squish_ife &lt;-<span class="st"> </span>function(x, a, b) {
  <span class="kw">ifelse</span>(x &lt;=<span class="st"> </span>a, a, <span class="kw">ifelse</span>(x &gt;=<span class="st"> </span>b, b, x))
}
squish_p &lt;-<span class="st"> </span>function(x, a, b) {
  <span class="kw">pmax</span>(<span class="kw">pmin</span>(x, b), a)
}
squish_in_place &lt;-<span class="st"> </span>function(x, a, b) {
  x[x &lt;=<span class="st"> </span>a] &lt;-<span class="st"> </span>a
  x[x &gt;=<span class="st"> </span>b] &lt;-<span class="st"> </span>b
  x
}

x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">100</span>, -<span class="fl">1.5</span>, <span class="fl">1.5</span>)
<span class="kw">microbenchmark</span>(
  <span class="dt">squish_ife      =</span> <span class="kw">squish_ife</span>(x, -<span class="dv">1</span>, <span class="dv">1</span>),
  <span class="dt">squish_p        =</span> <span class="kw">squish_p</span>(x, -<span class="dv">1</span>, <span class="dv">1</span>),
  <span class="dt">squish_in_place =</span> <span class="kw">squish_in_place</span>(x, -<span class="dv">1</span>, <span class="dv">1</span>),
  <span class="dt">unit =</span> <span class="st">&quot;us&quot;</span>
)
<span class="co">#&gt; Unit: microseconds</span>
<span class="co">#&gt;             expr   min    lq mean median   uq   max neval</span>
<span class="co">#&gt;       squish_ife 59.40 62.00 74.1   74.5 76.3 129.0   100</span>
<span class="co">#&gt;         squish_p 24.10 28.80 38.6   32.0 33.0 626.0   100</span>
<span class="co">#&gt;  squish_in_place  7.96  9.18 10.9   10.8 11.5  21.8   100</span></code></pre>
<p>Using <code>pmin()</code> and <code>pmax()</code> is about 3x faster than <code>ifelse()</code>, and using subsetting directly is about twice as fast again. We can often do even better by using C++. The following example compares the best R implementation to a relatively simple, if verbose, implementation in C++. Even if you’ve never used C++, you should still be able to follow the basic strategy: loop over every element in the vector and perform a different action depending on whether or not the value is less than <code>a</code> and/or greater than <code>b</code>. The C++ implementation is around 3x faster than the best pure R implementation.</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;Rcpp.h&gt;</span>
<span class="kw">using</span> <span class="kw">namespace</span> Rcpp;

<span class="co">// [[Rcpp::export]]</span>
NumericVector squish_cpp(NumericVector x, <span class="dt">double</span> a, <span class="dt">double</span> b) {
  <span class="dt">int</span> n = x.length();
  NumericVector out(n);

  <span class="kw">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; ++i) {
    <span class="dt">double</span> xi = x[i];
    <span class="kw">if</span> (xi &lt; a) {
      out[i] = a;
    } <span class="kw">else</span> <span class="kw">if</span> (xi &gt; b) {
      out[i] = b;
    } <span class="kw">else</span> {
      out[i] = xi;
    }
  }

  <span class="kw">return</span> out;
}</code></pre>
<p>(You’ll learn how to access this C++ code from R in <a href="Rcpp.html#rcpp">Rcpp</a>.)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">microbenchmark</span>(
  <span class="dt">squish_in_place =</span> <span class="kw">squish_in_place</span>(x, -<span class="dv">1</span>, <span class="dv">1</span>),
  <span class="dt">squish_cpp      =</span> <span class="kw">squish_cpp</span>(x, -<span class="dv">1</span>, <span class="dv">1</span>),
  <span class="dt">unit =</span> <span class="st">&quot;us&quot;</span>
)
<span class="co">#&gt; Unit: microseconds</span>
<span class="co">#&gt;             expr  min    lq  mean median    uq  max neval</span>
<span class="co">#&gt;  squish_in_place 10.1 10.70 11.51  11.00 11.20 22.5   100</span>
<span class="co">#&gt;       squish_cpp  5.2  5.56  6.12   5.75  5.97 27.7   100</span></code></pre>
<h3>Exercises</h3>
<ol style="list-style-type: decimal">
<li><p>The performance characteristics of <code>squish_ife()</code>, <code>squish_p()</code>, and <code>squish_in_place()</code> vary considerably with the size of <code>x</code>. Explore the differences. Which sizes lead to the biggest and smallest differences?</p></li>
<li><p>Compare the performance costs of extracting an element from a list, a column from a matrix, and a column from a data frame. Do the same for rows.</p></li>
</ol>
<h2 id="faster-r">Alternative R implementations</h2>
<p>There are some exciting new implementations of R. While they all try to stick as closely as possible to the existing language definition, they improve speed by using ideas from modern interpreter design. The four most mature open-source projects are: </p>
<ul>
<li><p><a href="http://www.pqr-project.org/">pqR</a> (pretty quick R) by Radford Neal. Built on top of R 2.15.0, it fixes many obvious performance issues, and provides better memory management and some support for automatic multithreading. </p></li>
<li><p><a href="http://www.renjin.org/">Renjin</a> by BeDataDriven. Renjin uses the Java virtual machine, and has an extensive <a href="http://packages.renjin.org/">test suite</a>. </p></li>
<li><p><a href="https://github.com/allr/fastr">FastR</a> by a team from Purdue. FastR is similar to Renjin, but it makes more ambitious optimisations and is somewhat less mature. </p></li>
<li><p><a href="https://github.com/jtalbot/riposte">Riposte</a> by Justin Talbot and Zachary DeVito. Riposte is experimental and ambitious. For the parts of R it implements, it is extremely fast. Riposte is described in more detail in <a href="http://www.justintalbot.com/wp-content/uploads/2012/10/pact080talbot.pdf">Riposte: A Trace-Driven Compiler and Parallel VM for Vector Code in R</a>. </p></li>
</ul>
<p>These are roughly ordered from most practical to most ambitious. Another project, <a href="http://www.cs.kent.ac.uk/projects/cxxr/">CXXR</a> by Andrew Runnalls, does not provide any performance improvements. Instead, it aims to refactor R’s internal C code in order to build a stronger foundation for future development, to keep behaviour identical to GNU-R, and to create better, more extensible documentation of its internals. </p>
<p>R is a huge language and it’s not clear whether any of these approaches will ever become mainstream. It’s a hard task to make an alternative implementation run all R code in the same way as GNU-R. Can you imagine having to reimplement every function in base R to be not only faster, but also to have exactly the same documented bugs? However, even if these implementations never make a dent in the use of GNU-R, they still provide benefits:</p>
<ul>
<li><p>Simpler implementations make it easy to validate new approaches before porting to GNU-R.</p></li>
<li><p>Knowing which aspects of the language can be changed with minimal impact on existing code and maximal impact on performance can help to guide us to where we should direct our attention.</p></li>
<li><p>Alternative implementations put pressure on the R-core to incorporate performance improvements.</p></li>
</ul>
<p>One of the most important approaches that pqR, Renjin, FastR, and Riposte are exploring is the idea of deferred evaluation. As Justin Talbot, the author of Riposte, points out: “for long vectors, R’s execution is completely memory bound. It spends almost all of its time reading and writing vector intermediates to memory”. If we could eliminate these intermediate vectors, we could improve performance and reduce memory usage. </p>
<p>The following example shows a very simple example of how deferred evaluation can help. We have three vectors, <code>x</code>, <code>y</code>, <code>z</code>, each containing 1 million elements, and we want to find the sum of <code>x</code> + <code>y</code> where <code>z</code> is TRUE. (This represents a simplification of a pretty common sort of data analysis question.)</p>
<pre class="sourceCode r"><code class="sourceCode r">x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="fl">1e6</span>)
y &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="fl">1e6</span>)
z &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(T, F), <span class="fl">1e6</span>, <span class="dt">rep =</span> <span class="ot">TRUE</span>)

<span class="kw">sum</span>((x +<span class="st"> </span>y)[z])</code></pre>
<p>In R, this creates two big temporary vectors: <code>x + y</code>, 1 million elements long, and <code>(x + y)[z]</code>, about 500,000 elements long. This means you need to have extra memory available for the intermediate calculation, and you have to shuttle the data back and forth between the CPU and memory. This slows computation down because the CPU can’t work at maximum efficiency if it’s always waiting for more data to come in.</p>
<p>However, if we rewrote the function using a loop in a language like C++, we only need one intermediate value: the sum of all the values we’ve seen:</p>
<pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#include &lt;Rcpp.h&gt;</span>
<span class="kw">using</span> <span class="kw">namespace</span> Rcpp;

<span class="co">// [[Rcpp::export]]</span>
<span class="dt">double</span> cond_sum_cpp(NumericVector x, NumericVector y, 
                    LogicalVector z) {
  <span class="dt">double</span> sum = <span class="dv">0</span>;
  <span class="dt">int</span> n = x.length();

  <span class="kw">for</span>(<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i++) {
    <span class="kw">if</span> (!z[i]) <span class="kw">continue</span>;
    sum += x[i] + y[i];
  }

  <span class="kw">return</span> sum;
}</code></pre>
<p>On my computer, this approach is about eight times faster than the vectorised R equivalent, which is already pretty fast.</p>
<pre class="sourceCode r"><code class="sourceCode r">cond_sum_r &lt;-<span class="st"> </span>function(x, y, z) {
  <span class="kw">sum</span>((x +<span class="st"> </span>y)[z])
}

<span class="kw">microbenchmark</span>(
  <span class="kw">cond_sum_cpp</span>(x, y, z),
  <span class="kw">cond_sum_r</span>(x, y, z),
  <span class="dt">unit =</span> <span class="st">&quot;ms&quot;</span>
)
<span class="co">#&gt; Unit: milliseconds</span>
<span class="co">#&gt;                   expr   min    lq  mean median    uq  max neval</span>
<span class="co">#&gt;  cond_sum_cpp(x, y, z)  7.21  7.49  7.61   7.61  7.66  9.5   100</span>
<span class="co">#&gt;    cond_sum_r(x, y, z) 27.20 29.80 31.77  31.40 31.70 77.4   100</span></code></pre>
<p>The goal of deferred evaluation is to perform this transformation automatically, so you can write concise R code and have it automatically translated into efficient machine code. Sophisticated translators can also figure out how to make the most of multiple cores. In the above example, if you have four cores, you could split <code>x</code>, <code>y</code>, and <code>z</code> into four pieces performing the conditional sum on each core, then adding together the four individual results. Deferred evaluation can also work with for loops, automatically discovering operations that can be vectorised.</p>
<p>This chapter has discussed some of the fundamental reasons that R is slow. The following chapters will give you the tools to do something about it when it impacts your code.</p>

        </div>
      </div>

      <div class="footer">
        <hr>
        <p>&copy; Hadley Wickham. Powered by <a href="http://jekyllrb.com/">jekyll</a>,
          <a href="http://yihui.name/knitr/">knitr</a>, and
          <a href="http://johnmacfarlane.net/pandoc/">pandoc</a>. Source
          available on <a href="https://github.com/hadley/adv-r/">github</a>.
        </p>
      </div>

    </div> <!-- /container -->

  <script src="//code.jquery.com/jquery.js"></script>
  <script src="www/bootstrap.min.js"></script>
  <script src="www/toc.js"></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-67989-16', 'had.co.nz');
    ga('send', 'pageview');

  </script>
  </body>
</html>
