
############################################################################
#
# Notes.-
#
############################################################################


1) The goal of this course

Raw data -> Processing script -> tidy data -> d. analysis -> d. communication


2) Definition of data

"Data are values of qualitative or quantitative variables, belonging to a set
of items (population)"


3) The four things you should have

   3.1) Raw data.

   3.2) Tidy data set

    a) There should be one table for each "kind" of variable

    b) If you have multiple tables, they should include a column in the table
      that allows them to be linked

    c) Include a row at the top of each file with variable names.

    d) In general data should be saved in one file per table.

    e) Each variable in a tidy dataset has been transformed to be interpretable.

    f) Numeric values in tidy data can not represent categories.

    g) Tidy data has no missing values.

    h) Tidy data has one variable per column. 




   3.3) Code Book: describing each variable and its values in the tidy dataset.

    a) Information about the variables (including units!) in the data set NOT
       CONTAINED in the tidy data.
    
    b) Information about the summary choices you made.

    c) Information about the experimental study design you used.

    c) A common format for this document is a Word/text file.

    d) Section "Study design": thorough description of how you collected the
    data.

    e) Section "Code book": describes each variable and its units.


   3.4) Instruction List: explicit and exact recipe to go from 1 -> 2,3.

    (Ideally) a computer script (R, python, ...)
    
    a) The input for the script is the raw data
    b) The output is the processed, tidy data
    c) There are no parameters to the script

    (If not possible) a detailed step by step list: step 1) do ...


4) Download data from the Internet

# Use function:
download.file() # Important parameters: url, destfile, method
# Note.- Be sure to record when you downloaded: date_downloaded <- date() 

# Example.- 
url_value <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD";
destfile_value <- "./cameras.csv";
method_value <- "wget"; #"curl";
download.file(url = url_value, destfile = destfile_value, method = method_value)

5) Reading local (flat) files

# Use function:
read.table()  # read.table("data.csv", sep = ",", header = TRUE)
read.csv()    # read.csv("data.csv")

Important parameters

* quote - you can tell R whether there are any quoted values quote="" means no
  quotes.
# The biggest trouble with reading flat files are quotation marks ` or " placed
# in data values, setting quote="" often resolves these.

* na.strings - set the character that represents a missing value.

* nrows - how many rows to read of the file (e.g. nrows=10 reads 10 lines).

* skip - number of lines to skip before starting to read


6) Reading local (excel) files

# Use function:
read.xlsx()  {xlsx package}
read.xlsx2() {xlsx package} # faster but can be unstable for reading for
			    # reading subsets of rows
write.xlsx() {xlsx package}
# i.e.
# library(xlsx)
# cameraDataSubset <- read.xlsx("cameras.xlsx", sheetIndex=1,
#                               colIndex=2:3, rowIndex= 1:4)

The XLConnect package has more options for writing and manipulating Excel files
The XLConnect vignette is a good place to start for that package



7) Reading XML

7.1) Read the file into R

# Use function:
xmlTreeParse()  {XML package} # generates an XML tree
xmlRoot
# i.e.
# library(XML)
# fileUrl <- "http://www.w3schools.com/xml/simple.xml"
# doc <- xmlTreeParse(fileUrl,useInternalnodes=TRUE)
# rootNode <- xmlRoot(doc)
# xmlName(rootNode)

7.2) DIRECTLY access parts of the XML document

rootNode[[1]]
rootNode[[1]][[1]]
# ... and so on 

7.3) PROGRAMATICALLY extract parts of the file

xmlSApply()
# Applies a function to each of the children of an XMLNode (wrapper of lapply)
# i.e.
xmlSApply(rootNode, xmlName)
xmlSApply(rootNode, xmlValue)

7.4) XPath: is a query language for selecting nodes from an XML document
# http://en.wikipedia.org/wiki/XPath
# http://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf

# i.e.
xpathApply()
xpathSApply(rootNode, "//price_label", xmlValue)


8) Reading JSON (Javascript Object Notation)

 Lightweight data storage
 Common format for data from APIs.
 Similar structure to XML but different syntax/format
 Data stored as: Numbers, Strings, Boolean, Array, Object
    
 http://en.wikipedia.org/wiki/JSON
 http://www.r-bloggers.com/new-package-jsonlite-a-smarter-json-encoderdecoder/
 
8.1) Reading data from JSON {jsonlite package}

fromJSON()  {jsonlite package} # R <- JSON string, URL or file
# i.e.
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
# [1] "id"                "name"              "full_name"         "owner" 
names(jsonData$owner) # Nested objects in JSON

8.2) Writing data frames to JSON {jsonlite package}

toJSON()  {jsonlite package} # JSON <- R
# i.e.
myjson <- toJSON(iris, pretty=TRUE)
cat(myjson)


9) data.table #{data.table package}

Inherets from data.frame
Much, much faster at subsetting, group, updating, and ordered joins

tables() #show all tables in memory

# example(data.table) # 

DT = data.table(x=rep(c("a","b","c"),each=3), y=c(1,3,6), v=1:9)
# > DT
#    x y v
# 1: a 1 1
# 2: a 3 2
# 3: a 6 3
# 4: b 1 4
# 5: b 3 5
# 6: b 6 6
# 7: c 1 7
# 8: c 3 8
# 9: c 6 9

9.1) Copy of tables 
#\warning: use SET methods: does not copy, but reference
DT_bis <- copy(DT)       # safe (set method) copy
DT_bis = DT              # does not copy, but reference

9.2) keys                 # sorts a ‘data.table’ and marks it as sorted.
setkey(DT,x)
setkeyv(DT,c("x"))

9.3) sub-setting

DT["a"]       # binary search (once ordered) # FASTER (for large tables) 
DT[x=="a"]    # vector scan                  # SLOW (for large tables)
#    x y v
# 1: a 1 1
# 2: a 3 2
# 3: a 6 3

DT[,sum(v),by=key(DT)]     # keyd by

9.4) joins

merge()

X = data.table(c("b","c"),foo=c(4,2))
# > X
#    V1 foo
# 1:  b   4
# 2:  c   2

> DT[X]           # join 
#    x y v foo
# 1: b 1 4   4
# 2: b 3 5   4
# 3: b 6 6   4
# 4: c 1 7   2
# 5: c 3 8   2
# 6: c 6 9   2

> setkey(DT,x,y)             # 2-column key
> DT[J("a",3:6)]             # join 2 keys, 4 rows (2 missing)
#    x y  v
# 1: a 3  2
# 2: a 4 NA
# 3: a 5 NA
# 4: a 6  3

#\warning  ".SD": working with subsets of a data.table
> DT[,.SD[2],by=x]           # 2nd row of each group
#    x y v
# 1: a 3 2
# 2: b 3 5
# 3: c 3 8

> DT[DT$x=="a"]
#    x y  v v2  m
# 1: a 1 42 NA 42
# 2: a 3 42 NA 42
# 3: a 6 42 NA 42

> DT[,sum(v),x][V1<20]       # compound query
#    x V1
# 1: a  6
# 2: b 15

> DT[!J("a")]                # not join

> DT[x!="b" | y!=3]          # multiple vector scanning approach, slow
> DT[!J("b",3)]              # same result but much faster


9.5) Add & remove elements to a table

> DT[, z:=42L]               # add new column by reference
> print(DT[,z:=42L])
#    x y v  z
# 1: a 1 1 42
> DT[,z:=NULL]               # remove column by reference
> DT[,m:=mean(v),by=x][]     # add new column by reference by group


9.6) Special vars. '.N': number of elements of a factor

# i.e. questions How many properties are worth $1,000,000 or more? 

> DT[, .N, by=x]
#    x N
# 1: a 3
# 2: b 3
# 3: c 3

9.7) Fast reading
fread("data.csv") #Similar to ‘read.table’ but FASTER and more convenient



############################################################################
#
# Glossary:
#
############################################################################

+ tidy: ordenado

+ thorough: minucioso
